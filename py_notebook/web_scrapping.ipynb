{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web_scrapping \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://swnsdigital.com/uk/2023/02/these-are-the-top-20-unwanted-fruit-and-vegetables-from-bagged-salad-leaves-to-bananas/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "\n",
    "# Find all <li> elements\n",
    "list_items = soup.find_all('li')\n",
    "\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "data = []\n",
    "\n",
    "# Iterate through each <li> element\n",
    "for li in list_items:\n",
    "    # Find <span> elements within the <li> element\n",
    "    span_elements = li.find_all('span')\n",
    "    # Extract the text content of each <span> element\n",
    "    span_texts = [span.text for span in span_elements]\n",
    "    # Add the extracted data to the list\n",
    "    data.append(span_texts)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(data)  # Adjust column names as needed\n",
    "\n",
    "# Print the DataFrame\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df= df.rename(columns={0:'top_fruit_veg_wasted'})\n",
    "df.to_csv('../source/top_fruit_veg_wasted.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_fruit_veg_wasted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad leaves (bagged)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lettuce (whole)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cucumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Carrots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mushrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Strawberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Spinach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oranges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Celery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Raspberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Onions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cabbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Blueberries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_fruit_veg_wasted\n",
       "0   Salad leaves (bagged)\n",
       "1                 Bananas\n",
       "2         Lettuce (whole)\n",
       "3                Cucumber\n",
       "4                Tomatoes\n",
       "5                 Carrots\n",
       "6               Mushrooms\n",
       "7                  Potato\n",
       "8                  Grapes\n",
       "9            Strawberries\n",
       "10                Spinach\n",
       "11                 Apples\n",
       "12                Oranges\n",
       "13               Broccoli\n",
       "14                Avocado\n",
       "15                 Celery\n",
       "16            Raspberries\n",
       "17                 Onions\n",
       "18                Cabbage\n",
       "19            Blueberries"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the URL\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_national_fruits'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table containing the data\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Extract data from the table\n",
    "rows = table.find_all('tr')\n",
    "data = []\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    row_data = []\n",
    "    for column in columns:\n",
    "        row_data.append(column.get_text().strip())  # Strip whitespace\n",
    "    if row_data:\n",
    "        data.append(row_data)\n",
    "\n",
    "# # Create DataFrame\n",
    "custom_headers = ['country', 'common_name','scientific_name','image','ref','notes']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data[1:], columns=custom_headers)\n",
    "# Display DataFrame\n",
    "df.columns\n",
    "df = df.drop(columns=[ 'scientific_name', 'image', 'ref', 'notes'])\n",
    "\n",
    "# df.to_csv('../source/national_fruit.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Send a GET request to the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/United_Nations_geoscheme_for_Europe\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Function to scrape countries for a given region\n",
    "def scrape_countries(region_name):\n",
    "    # Find the heading for the specified region\n",
    "    region_heading = soup.find('span', {'id': region_name})\n",
    "\n",
    "    # Find the div containing the list of countries for the specified region\n",
    "    region_div = region_heading.find_next('div', class_='div-col')\n",
    "\n",
    "    # Initialize a list to store countries\n",
    "    countries = []\n",
    "\n",
    "    # Loop through each list item in the div\n",
    "    for item in region_div.find_all('li'):\n",
    "        # Extract country name\n",
    "        country_name = item.text.split('\\xa0')[1]\n",
    "\n",
    "        # Append country name and region to the list\n",
    "        countries.append((country_name, region_name.replace(\"_\", \" \")))\n",
    "\n",
    "    return countries\n",
    "\n",
    "# Scrape countries for each region\n",
    "regions = ['Eastern_Europe', 'Northern_Europe', 'Southern_Europe', 'Western_Europe']\n",
    "combined_countries = []\n",
    "for region in regions:\n",
    "    combined_countries.extend(scrape_countries(region))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(combined_countries, columns=['Country', 'Region'])\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n",
    "df.to_csv('../source/country_region.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
