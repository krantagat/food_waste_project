{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krant\\AppData\\Local\\Temp\\ipykernel_17376\\3324755166.py:16: DtypeWarning: Columns (9,11,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bq_keywords = pd.read_csv('../source/bq_keywords_food_waste.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read from flat excel waste per category percentage\n",
    "df1_waste_cate_per = pd.read_excel('../source/waste_cate_per.xlsx', 'Sheet 1') \n",
    "df2_waste_cate_per = pd.read_excel('../source/waste_cate_per.xlsx', 'Sheet 2')\n",
    "\n",
    "#read from flat excel waste per category capita\n",
    "df1_waste_cate_cap = pd.read_excel('../source/waste_cate_capita.xlsx', 'Sheet 1') \n",
    "df2_waste_cate_cap = pd.read_excel('../source/waste_cate_capita.xlsx', 'Sheet 2')\n",
    "#read from flat excel food waste \n",
    "df1_food_waste = pd.read_excel('../source/food_waste.xlsx','Sheet 1')\n",
    "df2_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 2')\n",
    "df3_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 3')\n",
    "df4_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 4')\n",
    "\n",
    "\n",
    "#read from bigquery csv\n",
    "df_bq_keywords = pd.read_csv('../source/bq_keywords_food_waste.csv')\n",
    "\n",
    "\n",
    "#read from API csv\n",
    "df_api_12 = pd.read_csv('../source/api_data12.csv')\n",
    "df_api_12_3 = pd.read_csv('../source/api_data12_3.csv')\n",
    "\n",
    "df_top_fruit_veg_wasted = pd.read_csv('../source/top_fruit_veg_wasted.csv')\n",
    "\n",
    "df_national_fruit = pd.read_csv('../source/national_fruit.csv')\n",
    "df_country_region = pd.read_csv('../source/country_region.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eu_country = ['Albania',\n",
    "'Austria',\n",
    "'Belgium',\n",
    "'Bosnia and Herzegovina',\n",
    "'Bulgaria',\n",
    "'Croatia',\n",
    "'Cyprus',\n",
    "'Czechia',\n",
    "'Denmark',\n",
    "'Estonia',\n",
    "'Finland',\n",
    "'France',\n",
    "'Germany',\n",
    "'Greece',\n",
    "'Hungary',\n",
    "'Iceland',\n",
    "'Ireland',\n",
    "'Italy',\n",
    "'Latvia',\n",
    "'Lithuania',\n",
    "'Luxembourg',\n",
    "'Malta',\n",
    "'Montenegro',\n",
    "'Netherlands (Kingdom of the)',\n",
    "'North Macedonia',\n",
    "'Norway',\n",
    "'Poland',\n",
    "'Portugal',\n",
    "'Romania',\n",
    "'Serbia',\n",
    "'Slovakia',\n",
    "'Slovenia',\n",
    "'Spain',\n",
    "'Sweden',\n",
    "'Switzerland',\n",
    "'TÃ¼rkiye',\n",
    "'United Kingdom of Great Britain and Northern Ireland','Netherlands Antilles [former]','Kosovo',\n",
    "'Belgium',\n",
    "'Bulgaria',\n",
    "'Czechia',\n",
    "'Denmark',\n",
    "'Germany',\n",
    "'Estonia',\n",
    "'Ireland',\n",
    "'Greece',\n",
    "'Spain',\n",
    "'France',\n",
    "'Croatia',\n",
    "'Italy',\n",
    "'Cyprus',\n",
    "'Latvia',\n",
    "'Lithuania',\n",
    "'Luxembourg',\n",
    "'Hungary',\n",
    "'Malta',\n",
    "'Netherlands',\n",
    "'Austria',\n",
    "'Poland',\n",
    "'Portugal',\n",
    "'Romania',\n",
    "'Slovenia',\n",
    "'Slovakia',\n",
    "'Finland',\n",
    "'Sweden',\n",
    "'Iceland',\n",
    "'Norway',\n",
    "'Switzerland',\n",
    "'United Kingdom',\n",
    "'Bosnia and Herzegovina',\n",
    "'Montenegro',\n",
    "'North Macedonia',\n",
    "'Albania',\n",
    "'Serbia',\n",
    "'TÃ¼rkiye',\n",
    "'Kosovo*','Türkiye']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read from flat excel waste per category\n",
    " \n",
    "\n",
    "# Slice rows from index 8 to 48 of df1_waste_cate_per and reset the index, dropping the old index\n",
    "df_waste_per = df1_waste_cate_per[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste_per using the values from the 9th row of df1_waste_cate_per\n",
    "df_waste_per = df_waste_per.rename(columns=df1_waste_cate_per.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste_per and set all values in that column to 2020\n",
    "df_waste_per['year'] = 2020\n",
    "\n",
    "# Slice rows from index 8 to 48 of df2_waste_cate_per and reset the index, dropping the old index\n",
    "df_waste2 = df2_waste_cate_per[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste2 using the values from the 9th row of df2_waste_cate_per\n",
    "df_waste2 = df_waste2.rename(columns=df2_waste_cate_per.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste2 and set all values in that column to 2021\n",
    "df_waste2['year'] = 2021\n",
    "\n",
    "# Concatenate df_waste_per and df_waste2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_waste_per = pd.concat([df_waste_per, df_waste2]).reset_index(drop=True)\n",
    "\n",
    "df_waste_per\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_waste_per.columns[df_waste_per.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_waste_per_c = df_waste_per.drop(columns=nan_columns)\n",
    "\n",
    "df_waste_per_c = df_waste_per_c.rename(columns={'COICOP (Labels)':'country'})\n",
    "df_waste_per_c.columns = [col.lower().replace(' ', '_') for col in df_waste_per_c.columns]\n",
    "\n",
    "\n",
    "df_waste_per_c['id'] = df_waste_per_c.apply(lambda row: f'{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_waste_per_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'  # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_waste_per_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_waste_per_c = df_waste_per_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_waste_per_c.insert(0, column_to_move, moved_column)\n",
    "\n",
    "df_waste_per_c.columns\n",
    "# df_waste_cap_c.to_csv('../source/check.csv',index=False)\n",
    "\n",
    "# Mapping original column names to shortened names\n",
    "column_mapping = {\n",
    "    'alcoholic_beverages,_tobacco_and_narcotics': 'substances',\n",
    "    'clothing_and_footwear': 'clothing',\n",
    "    'housing,_water,_electricity,_gas_and_other_fuels': 'house_utilities',\n",
    "    'furnishings,_household_equipment_and_routine_household_maintenance': 'house_maintenance',\n",
    "    'recreation_and_culture': 'recreation_culture',\n",
    "    'restaurants_and_hotels': 'restaurants_hotels',\n",
    "    'non-alcoholic_beverages': 'beverages',\n",
    "    'miscellaneous_goods_and_services': 'miscellaneous'\n",
    "}\n",
    "\n",
    "# Rename columns using the mapping\n",
    "df_waste_per_c = df_waste_per_c.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from flat excel waste per category\n",
    " \n",
    "\n",
    "# Slice rows from index 8 to 48 of df1_waste_cate_cap and reset the index, dropping the old index\n",
    "df_waste_cap = df1_waste_cate_cap[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste_cap using the values from the 9th row of df1_waste_cate_cap\n",
    "df_waste_cap = df_waste_cap.rename(columns=df1_waste_cate_cap.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste_cap and set all values in that column to 2020\n",
    "df_waste_cap['year'] = 2020\n",
    "\n",
    "# Slice rows from index 8 to 48 of df2_waste_cate_cap and reset the index, dropping the old index\n",
    "df_waste2_cap = df2_waste_cate_cap[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste2_cap using the values from the 9th row of df2_waste_cate_cap\n",
    "df_waste2_cap = df_waste2_cap.rename(columns=df2_waste_cate_cap.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste2_cap and set all values in that column to 2021\n",
    "df_waste2_cap['year'] = 2021\n",
    "\n",
    "# Concatenate df_waste_cap and df_waste2_cap vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_waste_cap = pd.concat([df_waste_cap, df_waste2_cap]).reset_index(drop=True)\n",
    "\n",
    "df_waste_cap\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_waste_cap.columns[df_waste_cap.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_waste_cap_c = df_waste_cap.drop(columns=nan_columns)\n",
    "\n",
    "df_waste_cap_c = df_waste_cap_c.rename(columns={'COICOP (Labels)':'country'})\n",
    "df_waste_cap_c.columns = [col.lower().replace(' ', '_') for col in df_waste_cap_c.columns]\n",
    "\n",
    "\n",
    "df_waste_cap_c['id'] = df_waste_cap_c.apply(lambda row: f'{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_waste_cap_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'  # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_waste_cap_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_waste_cap_c = df_waste_cap_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_waste_cap_c.insert(0, column_to_move, moved_column)\n",
    "\n",
    "\n",
    "\n",
    "# Mapping original column names to shortened names\n",
    "column_mapping = {\n",
    "    'alcoholic_beverages,_tobacco_and_narcotics': 'substances',\n",
    "    'clothing_and_footwear': 'clothing',\n",
    "    'housing,_water,_electricity,_gas_and_other_fuels': 'house_utilities',\n",
    "    'furnishings,_household_equipment_and_routine_household_maintenance': 'house_maintenance',\n",
    "    'recreation_and_culture': 'recreation_culture',\n",
    "    'restaurants_and_hotels': 'restaurants_hotels',\n",
    "    'non-alcoholic_beverages': 'beverages',\n",
    "    'miscellaneous_goods_and_services': 'miscellaneous'\n",
    "}\n",
    "\n",
    "# Rename columns using the mapping\n",
    "df_waste_cap_c = df_waste_per_c.rename(columns=column_mapping)\n",
    "# df_waste_cap_c.to_csv('../source/check.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice rows from index 12 to 38 of df1_food_waste and reset the index, dropping the old index\n",
    "df_kilo_capita = df1_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_kilo_capita using the values from the 9th row of df1_food_waste\n",
    "df_kilo_capita = df_kilo_capita.rename(columns=df1_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_kilo_capita and set all values in that column to 2020\n",
    "df_kilo_capita['year'] = 2020\n",
    "\n",
    "# Slice rows from index 12 to 38 of df2_food_waste and reset the index, dropping the old index\n",
    "df_kilo_capita2 = df2_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_kilo_capita2 using the values from the 9th row of df2_food_waste\n",
    "df_kilo_capita2 = df_kilo_capita2.rename(columns=df2_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_kilo_capita2 and set all values in that column to 2021\n",
    "df_kilo_capita2['year'] = 2021\n",
    "\n",
    "# Concatenate df_kilo_capita and df_kilo_capita2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_kilo_capita = pd.concat([df_kilo_capita, df_kilo_capita2]).reset_index(drop=True)\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_kilo_capita.columns[df_kilo_capita.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_kilo_capita_c = df_kilo_capita.drop(columns=nan_columns)\n",
    "df_kilo_capita_c\n",
    "\n",
    "\n",
    "df_kilo_capita_c = df_kilo_capita_c.rename(columns={'NACE_R2 (Labels)':'country'})\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_kilo_capita_c.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_kilo_capita_c.columns]\n",
    "\n",
    "\n",
    "df_kilo_capita_c['id'] = df_kilo_capita_c.apply(lambda row: f'{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_kilo_capita_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_kilo_capita_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_kilo_capita_c = df_kilo_capita_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_kilo_capita_c.insert(0, column_to_move, moved_column)\n",
    "# Insert the column at the first position\n",
    "\n",
    "\n",
    "# Define the mapping of old names to new names\n",
    "column_mapping = {\n",
    "    'primary_production_of_food_-_agriculture,_fishing_and_aquaculture': 'food_production',\n",
    "    'manufacture_of_food_products_and_beverages': 'food_manufacture',\n",
    "    'retail_and_other_distribution_of_food': 'food_distribution',\n",
    "    'restaurants_and_food_services': 'food_services',\n",
    "    'total_activities_by_households': 'households'\n",
    "}\n",
    "\n",
    "# Use the replace function to rename columns\n",
    "df_kilo_capita_c.rename(columns=column_mapping, inplace=True)\n",
    "#cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice rows from index 10 to 38 of df3_food_waste and reset the index, dropping the old index\n",
    "df_tonne = df3_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_tonne using the values from the 9th row of df3_food_waste\n",
    "df_tonne = df_tonne.rename(columns=df3_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_tonne and set all values in that column to 2020\n",
    "df_tonne['year'] = 2020\n",
    "\n",
    "# Slice rows from index 10 to 38 of df4_food_waste and reset the index, dropping the old index\n",
    "df_tonne2 = df4_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_tonne2 using the values from the 9th row of df4_food_waste\n",
    "df_tonne2 = df_tonne2.rename(columns=df4_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_tonne2 and set all values in that column to 2021\n",
    "df_tonne2['year'] = 2021\n",
    "\n",
    "# Concatenate df_tonne and df_tonne2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_tonne = pd.concat([df_tonne, df_tonne2]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_tonne.columns[df_tonne.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_tonne_c = df_tonne.drop(columns=nan_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_tonne_c = df_tonne_c.rename(columns={'NACE_R2 (Labels)':'country'})\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_tonne_c.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_tonne_c.columns]\n",
    "\n",
    "\n",
    "df_tonne_c['id'] = df_tonne_c.apply(lambda row: f'{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_tonne_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_tonne_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_tonne_c = df_tonne_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_tonne_c.insert(0, column_to_move, moved_column)\n",
    "\n",
    "#claned\n",
    "df_tonne_c.columns.value_counts()\n",
    "\n",
    "# Define the mapping of old names to new names\n",
    "column_mapping = {\n",
    "    'primary_production_of_food_-_agriculture,_fishing_and_aquaculture': 'food_production',\n",
    "    'manufacture_of_food_products_and_beverages': 'food_manufacture',\n",
    "    'retail_and_other_distribution_of_food': 'food_distribution',\n",
    "    'restaurants_and_food_services': 'food_services',\n",
    "    'total_activities_by_households': 'total_household_activities'\n",
    "}\n",
    "\n",
    "# Use the replace function to rename columns\n",
    "df_tonne_c.rename(columns=column_mapping, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>meat</th>\n",
       "      <th>fish</th>\n",
       "      <th>dairy</th>\n",
       "      <th>eggs</th>\n",
       "      <th>cereals</th>\n",
       "      <th>fruits</th>\n",
       "      <th>vegetables</th>\n",
       "      <th>potatoes</th>\n",
       "      <th>oilcrops</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>production</td>\n",
       "      <td>0.00</td>\n",
       "      <td>136.50</td>\n",
       "      <td>14.90</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.02</td>\n",
       "      <td>26.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.24</td>\n",
       "      <td>184.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>production</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58.06</td>\n",
       "      <td>89.16</td>\n",
       "      <td>14.42</td>\n",
       "      <td>45.06</td>\n",
       "      <td>99.25</td>\n",
       "      <td>332.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.18</td>\n",
       "      <td>654.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Italy</td>\n",
       "      <td>production</td>\n",
       "      <td>0.00</td>\n",
       "      <td>66.46</td>\n",
       "      <td>33.45</td>\n",
       "      <td>14.76</td>\n",
       "      <td>18.99</td>\n",
       "      <td>811.30</td>\n",
       "      <td>868.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1813.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>20.13</td>\n",
       "      <td>27.89</td>\n",
       "      <td>43.63</td>\n",
       "      <td>1.35</td>\n",
       "      <td>16.42</td>\n",
       "      <td>7.81</td>\n",
       "      <td>24.05</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>148.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>186.69</td>\n",
       "      <td>80.37</td>\n",
       "      <td>218.16</td>\n",
       "      <td>16.90</td>\n",
       "      <td>212.97</td>\n",
       "      <td>135.46</td>\n",
       "      <td>270.29</td>\n",
       "      <td>192.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1313.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italy</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>143.55</td>\n",
       "      <td>37.75</td>\n",
       "      <td>139.81</td>\n",
       "      <td>13.59</td>\n",
       "      <td>44.71</td>\n",
       "      <td>679.84</td>\n",
       "      <td>570.32</td>\n",
       "      <td>10.97</td>\n",
       "      <td>59.23</td>\n",
       "      <td>1699.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country           type    meat    fish   dairy   eggs  cereals  fruits  \\\n",
       "0  Denmark     production    0.00  136.50   14.90   1.41     2.06    2.02   \n",
       "1  Germany     production    0.00   58.06   89.16  14.42    45.06   99.25   \n",
       "2    Italy     production    0.00   66.46   33.45  14.76    18.99  811.30   \n",
       "3  Denmark  manufacturing   20.13   27.89   43.63   1.35    16.42    7.81   \n",
       "4  Germany  manufacturing  186.69   80.37  218.16  16.90   212.97  135.46   \n",
       "5    Italy  manufacturing  143.55   37.75  139.81  13.59    44.71  679.84   \n",
       "\n",
       "   vegetables  potatoes  oilcrops    total  \n",
       "0       26.61      0.00      1.24   184.74  \n",
       "1      332.97      0.00     15.18   654.10  \n",
       "2      868.17      0.00      0.69  1813.81  \n",
       "3       24.05      9.45      0.00   148.73  \n",
       "4      270.29    192.46      0.01  1313.11  \n",
       "5      570.32     10.97     59.23  1699.78  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#read from text file \n",
    "df_composition = pd.read_csv('../source/food_composition.csv')\n",
    "\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_composition.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_composition.columns]\n",
    "df_composition_c = df_composition.drop(columns=['sugarbeets'])\n",
    "df_composition_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_bq_keywords_eu = df_bq_keywords[df_bq_keywords['geoareaname'].isin(eu_country)].reset_index(drop=True)\n",
    "\n",
    "#DROP EMPTY COLUMN\n",
    "df_bq_keywords_eu = df_bq_keywords_eu.drop(columns=['cities','education_level','freq','hazard_type','ihr_capacity','level_status','location','migratory_status','mode_of_transportation',\n",
    "'name_of_international_institution','name_of_non_communicable_disease','sex','tariff_regime_status','type_of_mobile_technology','type_of_occupation','type_of_skill','type_of_speed'])\n",
    "\n",
    "df_bq_keywords_eu['geoareaname'] = df_bq_keywords_eu['geoareaname'].replace(\"United Kingdom of Great Britain and Northern Ireland\", \"United Kingdom\")\n",
    "\n",
    "\n",
    "df_bq_keywords_eu['id'] = df_bq_keywords_eu.apply(lambda row: f'{row[\"geoareaname\"].lower()}{row[\"timeperiod\"]}', axis=1)\n",
    "# Assuming 'df_bq_keywords_eu' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_bq_keywords_eu[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_bq_keywords_eu = df_bq_keywords_eu.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_bq_keywords_eu.insert(0, column_to_move, moved_column)\n",
    "df_bq_keywords_eu = df_bq_keywords_eu.rename(columns={'geoareaname':'country'})\n",
    "df_bq_keywords_eu = df_bq_keywords_eu.rename(columns={'timeperiod':'year'})\n",
    "\n",
    "\n",
    "\n",
    "#droping target which is not related\n",
    "df_bq_keywords_eu['seriesdescription'].value_counts()\n",
    "rows_to_keep = [\n",
    "    \"Prevalence of severe food insecurity in the adult population (%)\",\n",
    "    \"Prevalence of moderate or severe food insecurity in the adult population (%)\",\n",
    "    \"Adult population in severe food insecurity (thousands of people)\",\n",
    "    \"Adult population in moderate or severe food insecurity (thousands of people)\"\n",
    "]\n",
    "\n",
    "# Filter DataFrame to keep only specified rows\n",
    "df_bq_food_target = df_bq_keywords_eu[df_bq_keywords_eu['seriesdescription'].isin(rows_to_keep)]\n",
    "\n",
    "\n",
    "#claned\n",
    "df_bq_food_target['seriesdescription'].value_counts()\n",
    "\n",
    "# Filter DataFrame for each condition and store in separate DataFrames\n",
    "df_severe_percent = df_bq_keywords_eu[df_bq_keywords_eu['seriesdescription'] == \"Prevalence of severe food insecurity in the adult population (%)\"].copy()\n",
    "df_moderate_food_percent = df_bq_keywords_eu[df_bq_keywords_eu['seriesdescription'] == \"Prevalence of moderate or severe food insecurity in the adult population (%)\"].copy()\n",
    "df_severe_population = df_bq_keywords_eu[df_bq_keywords_eu['seriesdescription'] == \"Adult population in severe food insecurity (thousands of people)\"].copy()\n",
    "df_moderate_population = df_bq_keywords_eu[df_bq_keywords_eu['seriesdescription'] == \"Adult population in moderate or severe food insecurity (thousands of people)\"].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_api_12_3['goal'] = df_api_12_3['goal'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['target'] = df_api_12_3['target'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['indicator'] = df_api_12_3['indicator'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['attributes'] = df_api_12_3['attributes'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12_3['dimensions'] = df_api_12_3['dimensions'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12_3['footnotes'] = df_api_12_3['footnotes'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_12_3_eu = df_api_12_3[df_api_12_3['geoAreaName'].isin(eu_country)].reset_index(drop=True)\n",
    "df_12_3_eu.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_12_3_eu.columns]\n",
    "\n",
    "#DROP EMPTY COLUMN\n",
    "df_12_3_eu = df_12_3_eu.drop(columns=['time_detail','timecoverage','upperbound','lowerbound','baseperiod','geoinfourl'])\n",
    "\n",
    "\n",
    "\n",
    "df_12_3_eu['timeperiodstart'] = df_12_3_eu['timeperiodstart'].astype(int)\n",
    "\n",
    "df_12_3_eu['geoareaname'] = df_12_3_eu['geoareaname'].replace(\"United Kingdom of Great Britain and Northern Ireland\", \"United Kingdom\")\n",
    "\n",
    "df_12_3_eu['geoareaname'] = df_12_3_eu['geoareaname'].replace(\"Netherlands (Kingdom of the)\", \"Netherlands\")\n",
    "\n",
    "\n",
    "\n",
    "df_12_3_eu['id'] = df_12_3_eu.apply(lambda row: f'{row[\"geoareaname\"].lower()}{row[\"timeperiodstart\"]}', axis=1)\n",
    "# Assuming 'df_12_3_eu' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_12_3_eu[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_12_3_eu = df_12_3_eu.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_12_3_eu.insert(0, column_to_move, moved_column)\n",
    "\n",
    "df_12_3_eu = df_12_3_eu.rename(columns={'geoareaname':'country'})\n",
    "df_12_3_eu = df_12_3_eu.rename(columns={'timeperiodstart':'year'})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "\n",
    "# df_top_fruit_veg_wasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_region\n",
    "df_country_region.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_country_region.columns]\n",
    "df_country_region\n",
    "\n",
    "\n",
    "df_country_region['country'] = df_country_region['country'].replace(\"United Kingdom of Great Britain and Northern Ireland\", \"United Kingdom\")\n",
    "\n",
    "# df_country_region['country'] = df_country_region['geoacountryreaname'].replace(\"Netherlands (Kingdom of the)\", \"Netherlands\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_national_fruit = pd.read_csv('../source/national_fruit.csv')\n",
    "# df_national_fruit.tail(30)\n",
    "\n",
    "\n",
    "df_national_fruit = df_national_fruit[df_national_fruit['country'].isin(eu_country)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_waste_per_c,df_waste_cap_c,\n",
    "# df_kilo_capita_c,\n",
    "# df_tonne_c,\n",
    "# df_composition,\n",
    "# df_bq_keywords_eu,\n",
    "# df_12_eu,\n",
    "# df_12_3_eu,\n",
    "# df_top_fruit_veg_wasted,\n",
    "# df_national_fruit,\n",
    "# df_country_region)\n",
    "\n",
    "dfs_to_save = {\n",
    "    'df_waste_per': df_waste_per_c,\n",
    "    'df_waste_cap': df_waste_cap_c,\n",
    "    'df_kilo_cap': df_kilo_capita_c,\n",
    "    'df_tonne_cap': df_tonne_c,\n",
    "    'df_composition': df_composition_c,\n",
    "    'df_12_3_eu': df_12_3_eu,\n",
    "    'df_top_wasted': df_top_fruit_veg_wasted,\n",
    "    'df_national_fruit': df_national_fruit,\n",
    "    'df_country_region': df_country_region,\n",
    "    'df_severe_percent': df_severe_percent,\n",
    "    'df_moderate_percent': df_moderate_food_percent,\n",
    "    'df_severe_population': df_severe_population,\n",
    "    'df_moderate_population': df_moderate_population\n",
    "}\n",
    "\n",
    "# Save each DataFrame with its name as the CSV file name\n",
    "for df_name, df in dfs_to_save.items():\n",
    "    df.to_csv(f\"../cleaned/{df_name}.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
