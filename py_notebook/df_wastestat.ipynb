{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krant\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "c:\\Users\\krant\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\krant\\AppData\\Local\\Temp\\ipykernel_17236\\4032773392.py:14: DtypeWarning: Columns (9,11,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_bq_keywords = pd.read_csv('../source/bq_keywords_food_waste.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read from flat excel waste per category\n",
    "df1_waste_cate = pd.read_excel('../source/waste_cate.xlsx', 'Sheet 1') \n",
    "df2_waste_cate = pd.read_excel('../source/waste_cate.xlsx', 'Sheet 2')\n",
    "#read from flat excel food waste \n",
    "df1_food_waste = pd.read_excel('../source/food_waste.xlsx','Sheet 1')\n",
    "df2_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 2')\n",
    "df3_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 3')\n",
    "df4_food_waste  = pd.read_excel('../source/food_waste.xlsx','Sheet 4')\n",
    "\n",
    "#read from text file \n",
    "df_composition = pd.read_csv('../source/food_composition.csv')\n",
    "\n",
    "#read from bigquery csv\n",
    "df_bq_keywords = pd.read_csv('../source/bq_keywords_food_waste.csv')\n",
    "\n",
    "\n",
    "#read from API csv\n",
    "df_api_12 = pd.read_csv('../source/api_data12.csv')\n",
    "df_api_12_3 = pd.read_csv('../source/api_data12_3.csv')\n",
    "\n",
    "df_top_fruit_veg_wasted = pd.read_csv('../source/top_fruit_veg_wasted.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eu_country = ['Albania',\n",
    "'Austria',\n",
    "'Belgium',\n",
    "'Bosnia and Herzegovina',\n",
    "'Bulgaria',\n",
    "'Croatia',\n",
    "'Cyprus',\n",
    "'Czechia',\n",
    "'Denmark',\n",
    "'Estonia',\n",
    "'Finland',\n",
    "'France',\n",
    "'Germany',\n",
    "'Greece',\n",
    "'Hungary',\n",
    "'Iceland',\n",
    "'Ireland',\n",
    "'Italy',\n",
    "'Latvia',\n",
    "'Lithuania',\n",
    "'Luxembourg',\n",
    "'Malta',\n",
    "'Montenegro',\n",
    "'Netherlands (Kingdom of the)',\n",
    "'North Macedonia',\n",
    "'Norway',\n",
    "'Poland',\n",
    "'Portugal',\n",
    "'Romania',\n",
    "'Serbia',\n",
    "'Slovakia',\n",
    "'Slovenia',\n",
    "'Spain',\n",
    "'Sweden',\n",
    "'Switzerland',\n",
    "'TÃ¼rkiye',\n",
    "'United Kingdom of Great Britain and Northern Ireland','Netherlands Antilles [former]','Kosovo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from flat excel waste per category\n",
    " \n",
    "\n",
    "# Slice rows from index 8 to 48 of df1_waste_cate and reset the index, dropping the old index\n",
    "df_waste = df1_waste_cate[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste using the values from the 9th row of df1_waste_cate\n",
    "df_waste = df_waste.rename(columns=df1_waste_cate.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste and set all values in that column to 2020\n",
    "df_waste['year'] = 2020\n",
    "\n",
    "# Slice rows from index 8 to 48 of df2_waste_cate and reset the index, dropping the old index\n",
    "df_waste2 = df2_waste_cate[11:49].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_waste2 using the values from the 9th row of df2_waste_cate\n",
    "df_waste2 = df_waste2.rename(columns=df2_waste_cate.iloc[7])\n",
    "\n",
    "# Add a new column named 'year' to df_waste2 and set all values in that column to 2021\n",
    "df_waste2['year'] = 2021\n",
    "\n",
    "# Concatenate df_waste and df_waste2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_waste = pd.concat([df_waste, df_waste2]).reset_index(drop=True)\n",
    "\n",
    "df_waste\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_waste.columns[df_waste.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_waste_c = df_waste.drop(columns=nan_columns)\n",
    "\n",
    "df_waste_c = df_waste_c.rename(columns={'COICOP (Labels)':'country'})\n",
    "df_waste_c.columns = [col.lower().replace(' ', '_') for col in df_waste_c.columns]\n",
    "\n",
    "\n",
    "df_waste_c['id'] = df_waste_c.apply(lambda row: f'waste_cat_{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_waste_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'  # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_waste_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_waste_c = df_waste_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_waste_c.insert(0, column_to_move, moved_column)\n",
    "# Insert the column at the first position\n",
    "\n",
    "# df_waste_c.to_csv('../source/check.csv',index=False)\n",
    "# df_waste_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice rows from index 12 to 38 of df1_food_waste and reset the index, dropping the old index\n",
    "df_kilo_capita = df1_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_kilo_capita using the values from the 9th row of df1_food_waste\n",
    "df_kilo_capita = df_kilo_capita.rename(columns=df1_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_kilo_capita and set all values in that column to 2020\n",
    "df_kilo_capita['year'] = 2020\n",
    "\n",
    "# Slice rows from index 12 to 38 of df2_food_waste and reset the index, dropping the old index\n",
    "df_kilo_capita2 = df2_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_kilo_capita2 using the values from the 9th row of df2_food_waste\n",
    "df_kilo_capita2 = df_kilo_capita2.rename(columns=df2_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_kilo_capita2 and set all values in that column to 2021\n",
    "df_kilo_capita2['year'] = 2021\n",
    "\n",
    "# Concatenate df_kilo_capita and df_kilo_capita2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_kilo_capita = pd.concat([df_kilo_capita, df_kilo_capita2]).reset_index(drop=True)\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_kilo_capita.columns[df_kilo_capita.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_kilo_capita_c = df_kilo_capita.drop(columns=nan_columns)\n",
    "df_kilo_capita_c\n",
    "\n",
    "\n",
    "df_kilo_capita_c = df_kilo_capita_c.rename(columns={'NACE_R2 (Labels)':'country'})\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_kilo_capita_c.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_kilo_capita_c.columns]\n",
    "\n",
    "\n",
    "df_kilo_capita_c['id'] = df_kilo_capita_c.apply(lambda row: f'waste_cat_{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_kilo_capita_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_kilo_capita_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_kilo_capita_c = df_kilo_capita_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_kilo_capita_c.insert(0, column_to_move, moved_column)\n",
    "# Insert the column at the first position\n",
    "\n",
    "\n",
    "\n",
    "#cleaned\n",
    "# df_kilo_capita_c.to_csv('../source/check.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice rows from index 10 to 38 of df3_food_waste and reset the index, dropping the old index\n",
    "df_tonne = df3_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_tonne using the values from the 9th row of df3_food_waste\n",
    "df_tonne = df_tonne.rename(columns=df3_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_tonne and set all values in that column to 2020\n",
    "df_tonne['year'] = 2020\n",
    "\n",
    "# Slice rows from index 10 to 38 of df4_food_waste and reset the index, dropping the old index\n",
    "df_tonne2 = df4_food_waste[12:39].reset_index(drop=True)\n",
    "\n",
    "# Rename the columns of df_tonne2 using the values from the 9th row of df4_food_waste\n",
    "df_tonne2 = df_tonne2.rename(columns=df4_food_waste.iloc[9])\n",
    "\n",
    "# Add a new column named 'year' to df_tonne2 and set all values in that column to 2021\n",
    "df_tonne2['year'] = 2021\n",
    "\n",
    "# Concatenate df_tonne and df_tonne2 vertically, stack them on top of each other, and reset the index, dropping the old index\n",
    "df_tonne = pd.concat([df_tonne, df_tonne2]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# First, find the column names that are NaN\n",
    "nan_columns = df_tonne.columns[df_tonne.columns.isna()]\n",
    "\n",
    "# Then drop these columns\n",
    "df_tonne_c = df_tonne.drop(columns=nan_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_tonne_c = df_tonne_c.rename(columns={'NACE_R2 (Labels)':'country'})\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_tonne_c.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_tonne_c.columns]\n",
    "\n",
    "\n",
    "df_tonne_c['id'] = df_tonne_c.apply(lambda row: f'waste_cat_{row[\"country\"].lower()}{row[\"year\"]}', axis=1)\n",
    "# Assuming 'df_tonne_c' is your DataFrame and 'column_to_move' is the name of the column you want to move to the first position\n",
    "column_to_move = 'id'   # Adjust this to the actual name of the column you want to move\n",
    "\n",
    "# Extract the column you want to move\n",
    "moved_column = df_tonne_c[column_to_move]\n",
    "\n",
    "# Drop the column from its original position\n",
    "df_tonne_c = df_tonne_c.drop(columns=[column_to_move])\n",
    "\n",
    "# Insert the column at the first position\n",
    "df_tonne_c.insert(0, column_to_move, moved_column)\n",
    "\n",
    "#claned\n",
    "# df_tonne_c.to_csv('../source/check.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_composition\n",
    "# Convert column names to lowercase, replace spaces with underscores, and replace parentheses with underscores\n",
    "df_composition.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_composition.columns]\n",
    "df_composition\n",
    "\n",
    "#claned ??\n",
    "# df_composition.to_csv('../source/check.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bq_keywords_eu = df_bq_keywords[df_bq_keywords['geoareaname'].isin(eu_country)].reset_index(drop=True)\n",
    "\n",
    "#DROP EMPTY COLUMN\n",
    "df_bq_keywords_eu = df_bq_keywords_eu.drop(columns=['cities','education_level','freq','hazard_type','ihr_capacity','level_status','location','migratory_status','mode_of_transportation',\n",
    "'name_of_international_institution','name_of_non_communicable_disease','sex','tariff_regime_status','type_of_mobile_technology','type_of_occupation','type_of_skill','type_of_speed'])\n",
    "\n",
    "\n",
    "#clean ??\n",
    "# df_bq_keywords_eu.to_csv('../source/check.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_api_12['goal'] = df_api_12['goal'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12['target'] = df_api_12['target'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12['indicator'] = df_api_12['indicator'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12['attributes'] = df_api_12['attributes'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12['dimensions'] = df_api_12['dimensions'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12['footnotes'] = df_api_12['footnotes'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "\n",
    "# df_api_12['value'] = df_api_12['value'].apply(lambda x: float(x))\n",
    "df_api_12['value'] = df_api_12['value'].apply(lambda x:int(x))\n",
    "\n",
    "df_12_eu = df_api_12[df_api_12['geoAreaName'].isin(eu_country)].reset_index(drop=True)\n",
    "\n",
    "df_12_eu.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_12_eu.columns]\n",
    "\n",
    "#DROP EMPTY COLUMN\n",
    "df_12_eu = df_12_eu.drop(columns=['time_detail','timecoverage','upperbound','lowerbound','geoinfourl'])\n",
    "\n",
    "#clean ??\n",
    "df_12_eu.to_csv('../source/check.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_api_12_3['goal'] = df_api_12_3['goal'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['target'] = df_api_12_3['target'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['indicator'] = df_api_12_3['indicator'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_api_12_3['attributes'] = df_api_12_3['attributes'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12_3['dimensions'] = df_api_12_3['dimensions'].apply(lambda x: x.replace('{','').replace('}','').replace(\"'\", ''))\n",
    "df_api_12_3['footnotes'] = df_api_12_3['footnotes'].apply(lambda x: x.replace('[','').replace(']','').replace(\"'\", ''))\n",
    "df_12_3_eu = df_api_12_3[df_api_12_3['geoAreaName'].isin(eu_country)].reset_index(drop=True)\n",
    "df_12_3_eu.columns = [col.lower().replace(' ', '_').replace('(', '@').replace(')', '@') for col in df_12_3_eu.columns]\n",
    "\n",
    "#DROP EMPTY COLUMN\n",
    "df_12_3_eu = df_12_3_eu.drop(columns=['time_detail','timecoverage','upperbound','lowerbound','baseperiod','geoinfourl'])\n",
    "\n",
    "#clean ??\n",
    "df_12_3_eu.to_csv('../source/check.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_fruit_veg_wasted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad leaves (bagged)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lettuce (whole)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cucumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Carrots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mushrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Strawberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Spinach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oranges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Celery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Raspberries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Onions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cabbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Blueberries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     top_fruit_veg_wasted\n",
       "0   Salad leaves (bagged)\n",
       "1                 Bananas\n",
       "2         Lettuce (whole)\n",
       "3                Cucumber\n",
       "4                Tomatoes\n",
       "5                 Carrots\n",
       "6               Mushrooms\n",
       "7                  Potato\n",
       "8                  Grapes\n",
       "9            Strawberries\n",
       "10                Spinach\n",
       "11                 Apples\n",
       "12                Oranges\n",
       "13               Broccoli\n",
       "14                Avocado\n",
       "15                 Celery\n",
       "16            Raspberries\n",
       "17                 Onions\n",
       "18                Cabbage\n",
       "19            Blueberries"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean\n",
    "df_top_fruit_veg_wasted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
